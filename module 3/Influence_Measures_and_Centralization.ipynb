{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIsNi+fIfU6Av2DoD3Js+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArthurCBx/Applied_Social_Network_Analysis/blob/main/module%203/Influence_Measures_and_Centralization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Degree and Closeness Centrality\n",
        "\n",
        "## Node Importance\n",
        "- Different ways of thinking about importance:\n",
        "  - Average proximity to other nodes;\n",
        "  - Number of connections;\n",
        "  - Fraction of shortest paths that pass through node\n",
        "\n",
        "## Network Centrality\n",
        "- Centrality measures identify the most important nodes in a netwrok:\n",
        "  - Influential nodes in a social network;\n",
        "  - Nodes that disseminate information to manu nodes or prevent epidemics;\n",
        "  - Hubs in a transportation network;\n",
        "  - Important pages on the Web;\n",
        "  - Nodes that prevent the network from breaking up;\n",
        "\n",
        "## Degree Centrality\n",
        "- **Assumption**: important nodes have many connections.\n",
        "  - For Undirected networks: use degree;\n",
        "  - Directed networks: use in-degree or out-degree\n",
        "  \n",
        "### Undirected Networks\n",
        "- $C_{deg}(v) = \\frac{d_v}{|N|-1}$, where $N$ is the set of nodes in the network and $d_v$ is the degree of node $v$\n",
        "```python\n",
        "# To get the degree centrality for all nodes\n",
        "degCent = nx.degree_centrality(G)\n",
        "degCent[34]\n",
        "```\n",
        "### Directed Networks\n",
        "- The fraction is the same but using number of in or out arrows.\n",
        "```python\n",
        "indegCent = nx.in_degree_centrality(G)\n",
        "```\n",
        "\n",
        "## Closeness Centrality\n",
        "- **Assumption**: important nodes are close to other nodes\n",
        "- $C_{close}(v) = \\frac{|N|-1}{\\sum_{u\\in N \\backslash {v}}{d(v,u)}}$, where N is the set of nodes in the network and d(u,v) is the length of the shortest path from v to u\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G)\n",
        "closeCent[32]\n",
        "```\n",
        "### Disconnected Nodes\n",
        "- How to measure the closeness centrality of a node when it cannot reach all other nodes?\n",
        "  - Option 1: Consider only nodes that node N can reach (Problematic)\n",
        "  - Option 2: Consider only nodes that node N can reach and normalize by the fraction of nodes N can reach (can reach/nodes-1).\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G,normalize=True)\n",
        "```\n",
        "\n",
        "## Closeness Centrality\n",
        "- **Assumption**: important nodes are close to other nodes\n",
        "- $C_{close}(v) = \\frac{|N|-1}{\\sum_{u\\in N \\backslash {v}}{d(v,u)}}$, where N is the set of nodes in the network and d(u,v) is the length of the shortest path from v to u\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G)\n",
        "closeCent[32]\n",
        "```\n",
        "### Disconnected Nodes\n",
        "- How to measure the closeness centrality of a node when it cannot reach all other nodes?\n",
        "  - Option 1: Consider only nodes that node N can reach (Problematic)\n",
        "  - Option 2: Consider only nodes that node N can reach and normalize by the fraction of nodes N can reach (can reach/nodes-1).\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G,normalize=True)\n",
        "```"
      ],
      "metadata": {
        "id": "vOooXrK3BSZs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gKKQxP3fBRN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Degree and Closeness Centrality\n",
        "\n",
        "## Node Importance\n",
        "- Different ways of thinking about importance:\n",
        "  - Average proximity to other nodes;\n",
        "  - Number of connections;\n",
        "  - Fraction of shortest paths that pass through node\n",
        "\n",
        "## Network Centrality\n",
        "- Centrality measures identify the most important nodes in a netwrok:\n",
        "  - Influential nodes in a social network;\n",
        "  - Nodes that disseminate information to manu nodes or prevent epidemics;\n",
        "  - Hubs in a transportation network;\n",
        "  - Important pages on the Web;\n",
        "  - Nodes that prevent the network from breaking up;\n",
        "\n",
        "## Degree Centrality\n",
        "- **Assumption**: important nodes have many connections.\n",
        "  - For Undirected networks: use degree;\n",
        "  - Directed networks: use in-degree or out-degree\n",
        "  \n",
        "### Undirected Networks\n",
        "- $C_{deg}(v) = \\frac{d_v}{|N|-1}$, where $N$ is the set of nodes in the network and $d_v$ is the degree of node $v$\n",
        "```python\n",
        "# To get the degree centrality for all nodes\n",
        "degCent = nx.degree_centrality(G)\n",
        "degCent[34]\n",
        "```\n",
        "### Directed Networks\n",
        "- The fraction is the same but using number of in or out arrows.\n",
        "```python\n",
        "indegCent = nx.in_degree_centrality(G)\n",
        "```\n",
        "\n",
        "## Closeness Centrality\n",
        "- **Assumption**: important nodes are close to other nodes\n",
        "- $C_{close}(v) = \\frac{|N|-1}{\\sum_{u\\in N \\backslash {v}}{d(v,u)}}$, where N is the set of nodes in the network and d(u,v) is the length of the shortest path from v to u\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G)\n",
        "closeCent[32]\n",
        "```\n",
        "### Disconnected Nodes\n",
        "- How to measure the closeness centrality of a node when it cannot reach all other nodes?\n",
        "  - Option 1: Consider only nodes that node N can reach (Problematic)\n",
        "  - Option 2: Consider only nodes that node N can reach and normalize by the fraction of nodes N can reach (can reach/nodes-1).\n",
        "\n",
        "```python\n",
        "closeCent = nx.closeness_centrality(G,normalize=True)\n",
        "```\n"
      ],
      "metadata": {
        "id": "uakKWl4T3UHF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkXC7WQXBJdR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zlGQSRwH3XPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Betweenness Centrality\n",
        "- **Assumption**: important nodes connect other nodes.\n",
        "\n",
        "## Connected Nodes\n",
        "- $C_{btw}(v) = \\sum_{S,t \\in N}\\frac{\\sigma_{S,t}(v)}{\\sigma_{S,t}}$\n",
        "    - $\\sigma_{S,t}=$ the number of shortest paths between nodes S and t\n",
        "    - $\\sigma_{S,t}(v)=$ the number of shortest paths between nodes S and t that pass through node $v$\n",
        "- **Endpoints**: We can either include or exclude node $v$ as node S and t in the computation of $C_{btw}(v)$\n",
        "\n",
        "## Disconnected Nodes\n",
        "- What if not all nodes can reach other ? This could lead to fractions divided by 0;\n",
        "- When computing betweenness centrality, we only consider nodes S, t such that there is at least one path between them.\n",
        "\n",
        "## Normalization\n",
        "- Betweenness centrality values will be larger in graphs with many nodes. To control for this, we divide centrality values by the number of pairs of nodes in the graph (excluding $v$):\n",
        "    - $\\frac{1}{2}(|N|-1)(|N|-2)$ in undirected graphs\n",
        "    - $(|N|-1)(|N|-2)$ in directed graphs\n",
        "\n",
        "### In Networkx\n",
        "```python\n",
        "btwnCent = nx.betweenness_centrality(G, normalized=True, endpoints=False)\n",
        "```\n",
        "\n",
        "## Complexity\n",
        "- Computing betweenness centrality of all nodes can be very computationally expensive;\n",
        "- Depending on the algorithm, this computation can take up to O(|N|³) time.\n",
        "- **Aproximation**: Rather than computing betweenness centrality based on all pairs of nodes S,t, we can approximate it based on a sample of nodes:\n",
        "    ```python\n",
        "    # K tells the number of nodes to use for the aproximation\n",
        "    nx.betweenness_centrality(G,normalized=True, endpoints=False, k=10)\n",
        "    # Returns a list with the betweenness centrality using random k nodes\n",
        "    ```\n",
        "- You can pass a subset to be used as approximation for source and target nodes:\n",
        "    ```python\n",
        "    # K tells the number of nodes to use for the aproximation\n",
        "    nx.betweenness_centrality_subset(G, [34,33,21,30,16,27,15,23,10], [1,4,13,11,6,12,17,7],    normalized=True)\n",
        "    # Returns a dict with the betweenness centrality using random k nodes, {node v: betweeness centrality}\n",
        "    ```\n",
        "\n",
        "## Betweenness Centrality - Edges\n",
        "- We can use betweenness centrality to find important edges instead of nodes\n",
        "- $C_{btw}(e) = \\sum_{S,t \\in N}\\frac{\\sigma_{S,t}(e)}{\\sigma_{S,t}}$, where:\n",
        "    - $\\sigma_{S,t}=$ the number of shortest paths between nodes S and t\n",
        "    - $\\sigma_{S,t}(e)=$ the number of shortest paths between nodes S and t that pass through edge $e$\n",
        "### In Networkx\n",
        "```python\n",
        "# Normal way to compute\n",
        "btwnCent = nx.edge_betweenness_centrality(G, normalized=True)\n",
        "\n",
        "# Computing using subsets\n",
        "nx.edge_betweenness_centrality(G,  [34,33,21,30,16,27,15,23,10], [1,4,13,11,6,12,17,7],\n",
        "normalized=True)\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vd6WWmRw3XV_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c3bBYqnR3Z90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWaoLAUL3aCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Page Rank\n",
        "\n",
        "## PageRank\n",
        "- Developed by Google founders to measure the importance of webpages from the hyperlink network structure;\n",
        "- PageRank assigns a score of importance to each node. Important nodes are those with many in-links from important pages;\n",
        "- PageRank can be used for any type of network, but it is mainly useful for directed networks.\n",
        "\n",
        "### How to measure\n",
        "- n = number of nodes in the network;\n",
        "- k = number of steps;\n",
        "1. Assign all nodes a PageRank of 1/n\n",
        "2. Perform the Basic PageRank Update Rule k times\n",
        "- **Basic PageRank Update Rule**: Each node gives an equal share of its current PageRank to all the nodes it links to;\n",
        "- The new PageRank of each node is the sum of all the PageRank it received from other nodes"
      ],
      "metadata": {
        "id": "Uh4hhJOp3aIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scaled PageRank\n",
        "## Interpreting PageRank\n",
        "- The PageRank of a node at step k is the probability that a **random walker** lands on the node after taking k steps.\n",
        "- **Random walk of k steps**: Start on a random node Then choose an outgoing edge at random and follow it to the next node. Repeat it k times.\n",
        "### PageRank Problem\n",
        "- Not strongly connected networks will make you stuck on a random walk, leaving the nodes you are stuck with, with higher PageRank and the other nodes with PageRank of 0.\n",
        "- **Damping Parameter ($\\alpha$)**: Start on a random node. Then:\n",
        "    - With probability $\\alpha$: choose an outgoing edge at random and follow it to the next node;\n",
        "    - With probability $(1-\\alpha)$: choose a node at random and go to it;\n",
        "    - Repeat K times\n",
        "### Scaled PageRank\n",
        "- The **Scaled PageRank** of k steps and damping factor $\\alpha$ of a node *n* is the probability that a random walk with damping factor $\\alpha$ lands on *n* after k steps;\n",
        "- As k gets larger, the Scaled PageRank converges to a value.\n",
        "\n",
        "## Networkx\n",
        "```python\n",
        "nx.pagerank(G, alpha=0.8)\n",
        "```"
      ],
      "metadata": {
        "id": "hDkvkiVn3b-5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bmu4WzHu3d9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A9-91_DW3eC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hubs and Authorities\n",
        "- Given a query to a search engine:\n",
        "    - **Root**: set of highly relevant web pages (e.g. pages that contain the query string) - potential authorities;\n",
        "    - Find all pages that link to a page in root - potential hubs;\n",
        "    - **Base**: root nodes and any node that links to a node in root;\n",
        "    - Consider all edges connecting nodes in the base set.\n",
        "## HITS Algorithm\n",
        "- Computing k iterations of the HITS algorithm to assign an authority score and hub score to each node;\n",
        "1. Assign each node an authority and hub score of 1;\n",
        "2. Apply the **Authority Update Rule**: each node's authority score is the sum of hub scores of each node that points to it;\n",
        "3. Apply the **Hub Update Rule**: each node's hub score is the sum of authority scores of each node that it points to;\n",
        "4. **Normalize** Authority and Hub scores: $auth(j) = \\frac{auth(j)}{\\sum_{i \\in N}auth(i)}$\n",
        "5. Repeat k times\n",
        "\n",
        "- In networkX: `nx.hits(G) -> [dict, dict]` returns hub and authority scores keyed by node"
      ],
      "metadata": {
        "id": "sEd4dMDc3eNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 3\n",
        "\n",
        "In this assignment you will explore measures of centrality on two networks, a friendship network in Part 1, and a blog network in Part 2."
      ],
      "metadata": {
        "id": "ZLuWsSLB3fb5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "\n",
        "Answer questions 1-4 using the network `G1`, a network of friendships at a university department. Each node corresponds to a person, and an edge indicates friendship.\n",
        "\n",
        "*The network has been loaded as networkx graph object `G1`.*"
      ],
      "metadata": {
        "id": "mq_A0MWL3geS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ArthurCBx/Applied_Social_Network_Analysis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4KcM7JY3ke-",
        "outputId": "efb3af7d-a223-45bf-b8e0-44a49ab5aa7b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Applied_Social_Network_Analysis' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "G1 = nx.read_gml('Applied_Social_Network_Analysis/module 3/friendships.gml')"
      ],
      "metadata": {
        "id": "rhhK4DPf3xiA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1\n",
        "\n",
        "Find the degree centrality, closeness centrality, and betweeness centrality of node 100.\n",
        "\n",
        "*This function should return a tuple of floats `(degree_centrality, closeness_centrality, betweenness_centrality)`.*"
      ],
      "metadata": {
        "id": "auCygaL540s7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_one():\n",
        "  return (nx.degree_centrality(G1)[100], nx.betweenness_centrality(G1)[100], nx.closeness_centrality(G1)[100])\n",
        "answer_one()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJQ0PM_S358K",
        "outputId": "c156e056-6a7b-4513-ca57-93c6f3db4b3f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0026501766784452294, 7.142902633244772e-05, 0.2654784240150094)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2\n",
        "\n",
        "Suppose you are employed by an online shopping website and are tasked with selecting one user in network G1 to send an online shopping voucher to. We expect that the user who receives the voucher will send it to their friends in the network.  You want the voucher to reach as many nodes as possible. The voucher can be forwarded to multiple users at the same time, but the travel distance of the voucher is limited to one step, which means if the voucher travels more than one step in this network, it is no longer valid. Apply your knowledge in network centrality to select the best candidate for the voucher.\n",
        "\n",
        "*This function should return an integer, the chosen node.*"
      ],
      "metadata": {
        "id": "45vX3_yy4yFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_two():\n",
        "  node, value = max(list(nx.degree_centrality(G1).items()), key=lambda x: x[1])\n",
        "  return node\n",
        "answer_two()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAA_RBbS4xk_",
        "outputId": "cada5e36-1221-4625-bfc5-e30612aa4978"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "105"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 3\n",
        "\n",
        "Now the limit of the voucher’s travel distance has been removed. Because the network is connected, regardless of who you pick, every node in the network will eventually receive the voucher. However, we now want to ensure that the voucher reaches nodes as quickly as possible (i.e. in the fewest number of hops). How will you change your selection strategy? Write a function to tell us who is the best candidate in the network under this condition.\n",
        "\n",
        "*This function should return an integer, the chosen node.*"
      ],
      "metadata": {
        "id": "shNECSO97h-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_three():\n",
        "  node, value = max(list(nx.closeness_centrality(G1).items()), key=lambda x: x[1])\n",
        "  return node\n",
        "answer_three()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vThCXtYC7jl7",
        "outputId": "16b77939-02ee-425e-d7d3-0c879e164cb8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4\n",
        "\n",
        "Assume the restriction on the voucher’s travel distance is still removed, but now a competitor has developed a strategy to remove a person from the network in order to disrupt the distribution of your company’s voucher. You competitor plans to remove people who act as bridges in the network. Identify the best possible person to be removed by your competitor?\n",
        "\n",
        "*This function should return an integer, the chosen node.*"
      ],
      "metadata": {
        "id": "RhPuSBzYDvQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_four():\n",
        "  node, value = max(list(nx.betweenness_centrality(G1).items()), key=lambda x: x[1])\n",
        "  return node\n",
        "answer_four()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCxAy6ZDDwYS",
        "outputId": "91137817-ca02-49b2-f3e9-6b4717c33270"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2\n",
        "\n",
        "`G2` is a directed network of political blogs, where nodes correspond to a blog and edges correspond to links between blogs. Use your knowledge of PageRank and HITS to answer Questions 5-9."
      ],
      "metadata": {
        "id": "3out9VuzEML4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G2 = nx.read_gml('Applied_Social_Network_Analysis/module 3/blogs.gml')"
      ],
      "metadata": {
        "id": "k9En3LYOELym"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 5\n",
        "\n",
        "Apply the Scaled Page Rank Algorithm to this network. Find the Page Rank of node 'realclearpolitics.com' with damping value 0.85.\n",
        "\n",
        "*This function should return a float.*"
      ],
      "metadata": {
        "id": "r059y8DzEW-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_five():\n",
        "  return nx.pagerank(G2,alpha=0.85)['realclearpolitics.com']\n",
        "answer_five()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W9Rbip1EYIW",
        "outputId": "d8bb254a-19f5-40b3-ee48-0e739f10006b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.004636694781649098"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 6\n",
        "\n",
        "Apply the Scaled Page Rank Algorithm to this network with damping value 0.85. Find the 5 nodes with highest Page Rank.\n",
        "\n",
        "*This function should return a list of the top 5 blogs in desending order of Page Rank.*"
      ],
      "metadata": {
        "id": "VY4_pqe1F4r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_six():\n",
        "  blog_pr_pair = sorted(nx.pagerank(G2,alpha=0.85).items(),key=lambda x:x[1],reverse=True)[:5]\n",
        "  return [blog for blog, pr in blog_pr_pair]\n",
        "answer_six()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nRo9VVCF6F2",
        "outputId": "5f051152-5949-45ed-e4ab-b1f8486dcef5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dailykos.com',\n",
              " 'atrios.blogspot.com',\n",
              " 'instapundit.com',\n",
              " 'blogsforbush.com',\n",
              " 'talkingpointsmemo.com']"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 7\n",
        "\n",
        "Apply the HITS Algorithm to the network to find the hub and authority scores of node 'realclearpolitics.com'.\n",
        "\n",
        "*Your result should return a tuple of floats `(hub_score, authority_score)`.*"
      ],
      "metadata": {
        "id": "_m3Y2bhrH-e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_seven():\n",
        "  hub_score, authority_score = nx.hits(G2)\n",
        "  return hub_score['realclearpolitics.com'], authority_score['realclearpolitics.com']\n",
        "answer_seven()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJND4PK4fl6y",
        "outputId": "cfe13839-aee7-4bca-f648-e0fa9ec8979f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0003243556140278732, 0.003918957644934254)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 8\n",
        "\n",
        "Apply the HITS Algorithm to this network to find the 5 nodes with highest hub scores.\n",
        "\n",
        "*This function should return a list of the top 5 blogs in desending order of hub scores.*"
      ],
      "metadata": {
        "id": "n_FDs629gO_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_eight():\n",
        "  hub_score, authority_score = nx.hits(G2)\n",
        "  top_five = sorted(hub_score.items(),key=lambda x: x[1], reverse=True)[:5]\n",
        "  return [blog for blog,value in top_five]\n",
        "answer_eight()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vay5bI65gZOA",
        "outputId": "2cb37470-2cf0-47d2-cc36-53905415cf48"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['politicalstrategy.org',\n",
              " 'madkane.com/notable.html',\n",
              " 'liberaloasis.com',\n",
              " 'stagefour.typepad.com/commonprejudice',\n",
              " 'bodyandsoul.typepad.com']"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 9\n",
        "\n",
        "Apply the HITS Algorithm to this network to find the 5 nodes with highest authority scores.\n",
        "\n",
        "*This function should return a list of the top 5 blogs in desending order of authority scores.*"
      ],
      "metadata": {
        "id": "lzapEhXbiVNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_nine():\n",
        "  hub_score, authority_score = nx.hits(G2)\n",
        "  top_five = sorted(authority_score.items(),key=lambda x: x[1], reverse=True)[:5]\n",
        "  return [blog for blog,value in top_five]\n",
        "answer_nine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOR__WP6iWcC",
        "outputId": "2006c042-b24b-41be-f566-15a389733966"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['dailykos.com',\n",
              " 'talkingpointsmemo.com',\n",
              " 'atrios.blogspot.com',\n",
              " 'washingtonmonthly.com',\n",
              " 'talkleft.com']"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    }
  ]
}